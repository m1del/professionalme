{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 20:57:36.528646: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 20:57:36.619747: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from shutil import unpack_archive\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 29 20:57:39 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 31%   34C    P8               5W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 31%   33C    P8               3W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:60:00.0 Off |                  N/A |\n",
      "| 31%   34C    P8               5W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 31%   37C    P8              15W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 31%   33C    P8              17W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 31%   34C    P8              21W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:DA:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8               2W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:DB:00.0 Off |                  N/A |\n",
      "| 31%   32C    P8              16W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Data Path\n",
    "DATA_PATH = '../data/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given Meta Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get meta data\n",
    "lfw_allnames = pd.read_csv(\"../data/lfw-dataset/lfw_allnames.csv\")\n",
    "matchpairsDevTest = pd.read_csv(\"../data/lfw-dataset/matchpairsDevTest.csv\")\n",
    "matchpairsDevTrain = pd.read_csv(\"../data/lfw-dataset/matchpairsDevTrain.csv\")\n",
    "mismatchpairsDevTest = pd.read_csv(\"../data/lfw-dataset/mismatchpairsDevTest.csv\")\n",
    "mismatchpairsDevTrain = pd.read_csv(\"../data/lfw-dataset/mismatchpairsDevTrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- pairs.csv: Contains randomly generated splits for 10-fold cross validation specifically for pairs. Use this for the image restricted configuration when forming training sets (refer to readme). There are 10 total sets; 5 sets contain 300 matched pairs, the other 5 sets contain 300 mismatched pairs.\n",
    "\n",
    "- people.csv: Contains randomly generated splits for 10-fold cross validation specifically for individual faces. Use this for the unrestricted configuration when forming training sets (refer to readme). There are 10 total sets, each with a different amount of people; Set 1: 601. Set 2: 555. Set 3: 552. Set 4: 560. Set 5: 567. Set 6: 527. Set 7: 597. Set 8: 601. Set 9: 580. Set 10: 609.\n",
    "\n",
    "- matchpairsDevTest.csv: Use this testing set if you decide to go with the pairs configuration. Contains 500 matched pairs of faces for testing set.\n",
    "\n",
    "- matchpairsDevTrain.csv: Use this training set if you decide to go with the pairs configuration. Contains 1100 matched pairs of faces for training set.\n",
    "\n",
    "- mismatchpairsDevTest.csv: Use this testing set if you decide to go with the pairs configuration. Contains 500 mismatched pairs of faces for testing set.\n",
    "\n",
    "- mismatchpairsDevTrain.csv: Use this training set f you decide to go with the pairs configuration. Contains 1100 mismatched pairs of faces for training set.\n",
    "\n",
    "- peopleDevTest.csv: Use this testing test if you decide to go with the people configuration. Contains 1711 people and 3708 images.\n",
    "\n",
    "- peopleDevTrain.csv: Use this training set if you decide to go with the people configuration. Contains 4038 people and 9525 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"../data/lfw-dataset/pairs.csv\")\n",
    "# tidy pairs data: \n",
    "pairs = pairs.rename(columns ={'name': 'name1', 'Unnamed: 3': 'name2'})\n",
    "matched_pairs = pairs[pairs[\"name2\"].isnull()].drop(\"name2\",axis=1)\n",
    "mismatched_pairs = pairs[pairs[\"name2\"].notnull()]\n",
    "people = pd.read_csv(\"../data/lfw-dataset/people.csv\")\n",
    "# remove null values\n",
    "people = people[people.name.notnull()]\n",
    "peopleDevTest = pd.read_csv(\"../data/lfw-dataset/peopleDevTest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lfwallnames.csv:** Contains all names of each face in the dataset along with number of images each face has.\n",
    "\n",
    "- **lfwreadme.csv:** Comprehensive readme file found on the original database. If there is any information you are missing here or are looking for additional resources you will probably find it in this file. It explains how each .csv file comes into play when forming training and testing models, as well as column metadata information for figuring out what the .csv is talking about. The original website also gives recommendations on training/testing splits and comparison benchmarks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique celbrities:  5749\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique celbrities: \",len(lfw_allnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celebrities with multiple images:  1680\n"
     ]
    }
   ],
   "source": [
    "print(\"Celebrities with multiple images: \", sum(lfw_allnames.images > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most photographed celebrities:                     name  images\n",
      "1871      George_W_Bush     530\n",
      "1047       Colin_Powell     236\n",
      "5458         Tony_Blair     144\n",
      "1404    Donald_Rumsfeld     121\n",
      "1892  Gerhard_Schroeder     109\n",
      "373        Ariel_Sharon      77\n",
      "2175        Hugo_Chavez      71\n",
      "2941  Junichiro_Koizumi      60\n",
      "2468      Jean_Chretien      55\n",
      "2682      John_Ashcroft      53\n"
     ]
    }
   ],
   "source": [
    "print(\" Most photographed celebrities: \", lfw_allnames.sort_values(by=\"images\",ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(name, number, data_path=DATA_PATH):\n",
    "    \"\"\"\n",
    "    Load an image from the dataset.\n",
    "    :param name: Name of the person.\n",
    "    :param number: Image number for the person.\n",
    "    :param data_path: Base directory of the LFW dataset.\n",
    "    :return: The loaded image.\n",
    "    \"\"\"\n",
    "    filename = f\"{name}_{number:04d}.jpg\"\n",
    "    filepath = os.path.join(data_path, name, filename)\n",
    "    image = cv2.imread(filepath)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess the image by resizing and normalizing.\n",
    "    :param image: The image to preprocess.\n",
    "    :param target_size: The target size of the image.\n",
    "    :return: Preprocessed image.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(data_path, allnames, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Create a dataset of images and labels.\n",
    "    :param data_path: Base directory of the LFW dataset.\n",
    "    :param allnames: DataFrame containing names and number of images.\n",
    "    :param target_size: Target size for each image.\n",
    "    :return: List of preprocessed images and labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in allnames.iterrows():\n",
    "        name = row['name']\n",
    "        for i in range(1, row['images'] + 1):\n",
    "            image = load_image(name, i, data_path)\n",
    "            image = preprocess_image(image, target_size)\n",
    "            images.append(image)\n",
    "            labels.append(name)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Create the dataset\n",
    "images, labels = create_dataset(DATA_PATH, lfw_allnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13233, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13233,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 20:58:15.323332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 20:58:15.794205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9803 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2023-11-29 20:58:15.794990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9803 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n",
      "2023-11-29 20:58:15.795693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9803 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:60:00.0, compute capability: 7.5\n",
      "2023-11-29 20:58:15.796375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 9803 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:61:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def build_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Build a simple CNN model for classification.\n",
    "    :param input_shape: Shape of the input images.\n",
    "    :return: Compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')  # Assuming classification\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 20:58:30.515589: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/__main__.py\", line 5, in <module>\n      app.launch_new_instance()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/scratch/local/16765705/ipykernel_2664338/4106594929.py\", line 11, in <module>\n      history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1028, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 676, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to float is not supported\n\t [[{{node Cast_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1328]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X_train, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# 0.25 x 0.8 = 0.2\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/__main__.py\", line 5, in <module>\n      app.launch_new_instance()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/scratch/local/16765705/ipykernel_2664338/4106594929.py\", line 11, in <module>\n      history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1028, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/blue/egn4951/jmiclat/professionalme/conda/envs/profme/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 676, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\n2 root error(s) found.\n  (0) UNIMPLEMENTED:  Cast string to float is not supported\n\t [[{{node Cast_1}}]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1328]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}, Test loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My ENV",
   "language": "python",
   "name": "hfrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
